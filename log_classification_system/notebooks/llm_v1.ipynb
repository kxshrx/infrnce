{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6245d633-0017-451a-ae8a-19dd00df54ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc846c-e0a6-4202-b646-ee45415cd788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .env from: /Users/kxshrx/dev/log-classification/.env\n",
      "Groq API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = os.path.abspath(os.path.join(os.getcwd(), '../.env'))\n",
    "print(f\"Loading .env from: {dotenv_path}\")\n",
    "\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "api_key = os.getenv('GROQ_API_KEY')\n",
    "if api_key and api_key != 'your_groq_api_key_here':\n",
    "    print(\"Groq API key loaded successfully\")\n",
    "else:\n",
    "    print(\"Please set your GROQ_API_KEY in the .env file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26911d83-52d3-49a4-ac6f-63289f835dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The translation of \"I love programming\" to French is:\n",
      "\n",
      "\"J'adore le programmation.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize the chat LLM\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.0,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Prepare chat messages as list of tuples (role, content)\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "\n",
    "# Invoke the model\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(\"Response:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c1a5a-f777-48e8-a989-5ee4a25f35af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analysis:\n",
      "Total logs: 61950\n",
      "Regex classified: 36537\n",
      "BERT classified: 14166\n",
      "Remaining for LLM: 14972\n",
      "\n",
      "Sample logs for LLM classification:\n",
      "1. WARNING oslo.service.loopingcall [-] Function 'nova.virt.libvirt.driver.LibvirtDriver.spawn.<locals>...\n",
      "2. ERROR nova.compute.manager [instance: c265f382-e5d8-44fb-98c8-84abd4592037]     self.force_reraise()...\n",
      "3. <entry name='serial'>f41265c7-0cc0-4212-8ab4-89626d362895</entry>...\n"
     ]
    }
   ],
   "source": [
    "# Load your BERT-processed dataset\n",
    "df = pd.read_csv('../results/nova_logs_with_bert.csv')\n",
    "\n",
    "unclassified_logs = df[\n",
    "    (df['regex_label'].isnull()) & \n",
    "    (df['bert_label'].isnull())\n",
    "].copy()\n",
    "\n",
    "print(f\"Data Analysis:\")\n",
    "print(f\"Total logs: {len(df)}\")\n",
    "print(f\"Regex classified: {df['regex_label'].notnull().sum()}\")\n",
    "print(f\"BERT classified: {df['bert_label'].notnull().sum()}\")\n",
    "print(f\"Remaining for LLM: {len(unclassified_logs)}\")\n",
    "\n",
    "print(f\"\\nSample logs for LLM classification:\")\n",
    "for i, log in enumerate(unclassified_logs['raw_log_text'].head(3), 1):\n",
    "    print(f\"{i}. {log[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546656b-0cb6-49f4-83fd-e6ac38829f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Groq client initialized successfully\n",
      "Using model: llama-3.3-70b-versatile\n",
      "Connection test: Connection successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "try:\n",
    "    llm = ChatGroq(\n",
    "        groq_api_key=os.getenv('GROQ_API_KEY'),\n",
    "        model_name=os.getenv('GROQ_MODEL', 'llama-3.3-70b-versatile'),\n",
    "        temperature=0.3,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    \n",
    "    print(\"LangChain Groq client initialized successfully\")\n",
    "    print(f\"Using model: {os.getenv('GROQ_MODEL', 'llama-3.3-70b-versatile')}\")\n",
    "    \n",
    "    test_response = llm.invoke([HumanMessage(content=\"Hello, respond with 'Connection successful'\")])\n",
    "    print(f\"Connection test: {test_response.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error initializing LangChain Groq client: {e}\")\n",
    "    print(\"Please check your API key in .env file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3797001d-fde3-455b-8291-f70cb03e3e7e",
   "metadata": {},
   "source": [
    "# Define Pydantic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfda0749-8db4-4cfd-9842-6776d805a7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pydantic LogClassification model defined\n",
      "Model fields: ['category', 'confidence', 'reasoning']\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define Pydantic output structure\n",
    "class LogClassification(BaseModel):\n",
    "    category: str = Field(..., description=\"The classification category\")\n",
    "    confidence: float = Field(..., ge=0.0, le=1.0, description=\"Confidence score between 0 and 1\")\n",
    "    reasoning: str = Field(..., description=\"Brief explanation for the classification\")\n",
    "\n",
    "print(\"Pydantic LogClassification model defined\")\n",
    "print(f\"Model fields: {list(LogClassification.model_fields.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3238ad3-0344-45cb-ae54-ce2d68f8f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples extracted by category\n",
      "  System_Operations: 27 examples\n",
      "  Instance_Management: 75 examples\n",
      "  Network_Operations: 68 examples\n",
      "  Resource_Management: 0 examples\n",
      "  Scheduler_Operations: 30 examples\n",
      "  Error_Handling: 0 examples\n"
     ]
    }
   ],
   "source": [
    "def get_examples_by_category(df):\n",
    "    \"\"\"Get real examples from your dataset by category\"\"\"\n",
    "    \n",
    "    # Get regex examples\n",
    "    regex_examples = df[df['regex_label'].notnull()]\n",
    "    bert_examples = df[df['bert_label'].notnull()]\n",
    "    \n",
    "    category_examples = {\n",
    "        'System_Operations': [],\n",
    "        'Instance_Management': [],\n",
    "        'Network_Operations': [],\n",
    "        'Resource_Management': [],\n",
    "        'Scheduler_Operations': [],\n",
    "        'Error_Handling': []\n",
    "    }\n",
    "    \n",
    "    # Add regex examples\n",
    "    for _, row in regex_examples.head(100).iterrows():  # Limit for speed\n",
    "        if 'System_Operations' in str(row['regex_label']):\n",
    "            category_examples['System_Operations'].append(row['raw_log_text'])\n",
    "        elif 'Instance_Management' in str(row['regex_label']):\n",
    "            category_examples['Instance_Management'].append(row['raw_log_text'])\n",
    "    \n",
    "    # Add BERT examples\n",
    "    for _, row in bert_examples.head(100).iterrows():  # Limit for speed\n",
    "        category = row['bert_label']\n",
    "        if category in category_examples:\n",
    "            category_examples[category].append(row['raw_log_text'])\n",
    "    \n",
    "    return category_examples\n",
    "\n",
    "# Extract examples\n",
    "examples_by_category = get_examples_by_category(df)\n",
    "\n",
    "print(\"Examples extracted by category\")\n",
    "for category, examples in examples_by_category.items():\n",
    "    print(f\"  {category}: {len(examples)} examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9724a4a5-4d3c-496b-879e-28a187285695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random examples selected\n",
      "  System_Operations: 2 selected\n",
      "    Sample: INFO nova.virt.libvirt.driver [req-c081868d-4495-4a56-adaa-3...\n",
      "  Instance_Management: 2 selected\n",
      "    Sample: INFO nova.compute.manager [None req-77b899cc-1990-4518-8ca6-...\n",
      "  Network_Operations: 2 selected\n",
      "    Sample: INFO os_vif [req-2b352c90-31b9-440d-8dfd-83a797a95e41] Succe...\n",
      "  Resource_Management: 1 selected\n",
      "    Sample: INFO nova.compute.claims [req-jkl] Claim successful...\n",
      "  Scheduler_Operations: 2 selected\n",
      "    Sample: ERROR nova.compute.manager [instance: 80cd044d-b8f2-4dab-b6b...\n",
      "  Error_Handling: 1 selected\n",
      "    Sample: ERROR nova.compute.manager [instance: xyz] File not found...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def select_random_examples(category_examples, n_per_category=2):\n",
    "    \"\"\"Randomly select examples for each category\"\"\"\n",
    "    \n",
    "    selected = {}\n",
    "    \n",
    "    for category, examples in category_examples.items():\n",
    "        if len(examples) > 0:\n",
    "            # Select random examples\n",
    "            n_select = min(n_per_category, len(examples))\n",
    "            selected[category] = random.sample(examples, n_select)\n",
    "        else:\n",
    "            # Fallback if no examples\n",
    "            fallback = {\n",
    "                'System_Operations': [\"INFO nova.virt.libvirt.driver [req-abc] Creating image\"],\n",
    "                'Instance_Management': [\"INFO nova.compute.manager [req-def] VM Started\"],\n",
    "                'Network_Operations': [\"INFO os_vif [req-ghi] Successfully plugged vif\"],\n",
    "                'Resource_Management': [\"INFO nova.compute.claims [req-jkl] Claim successful\"],\n",
    "                'Scheduler_Operations': [\"INFO nova.scheduler.client.report [req-mno] Deleted allocation\"],\n",
    "                'Error_Handling': [\"ERROR nova.compute.manager [instance: xyz] File not found\"]\n",
    "            }\n",
    "            selected[category] = [fallback[category][0]]\n",
    "    \n",
    "    return selected\n",
    "\n",
    "# Select random examples\n",
    "selected_examples = select_random_examples(examples_by_category, n_per_category=2)\n",
    "\n",
    "print(\"Random examples selected\")\n",
    "for category, examples in selected_examples.items():\n",
    "    print(f\"  {category}: {len(examples)} selected\")\n",
    "    if examples:\n",
    "        print(f\"    Sample: {examples[0][:60]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c7e3337-4a2c-4e0c-b2ee-c00264ad6072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples formatted for prompt\n",
      "Formatted examples length: 1237 characters\n",
      "\n",
      "Sample formatted examples:\n",
      "System_Operations: \"INFO nova.virt.libvirt.driver [req-c081868d-4495-4a56-adaa-349c1e09b072] [instance: 56b8e26a-1ce7-460d-a6e5-d60f2ffbf7fc...\"\n",
      "System_Operations: \"INFO nova.virt.libvirt.driver [req-3a04b6a9-5a46-409e-ab95-cfbea20059aa] [instance: ba40f9c5-a0d8-4922-9e3a-8d4904ce797c...\"\n",
      "Instance_M...\n"
     ]
    }
   ],
   "source": [
    "def format_examples_for_prompt(selected_examples):\n",
    "    \"\"\"Format examples into prompt text\"\"\"\n",
    "    \n",
    "    examples_text = []\n",
    "    \n",
    "    for category, example_logs in selected_examples.items():\n",
    "        for log in example_logs:\n",
    "            # Truncate long logs\n",
    "            truncated = log[:120] + \"...\" if len(log) > 120 else log\n",
    "            examples_text.append(f\"{category}: \\\"{truncated}\\\"\")\n",
    "    \n",
    "    return \"\\n\".join(examples_text)\n",
    "\n",
    "# Format examples\n",
    "formatted_examples = format_examples_for_prompt(selected_examples)\n",
    "\n",
    "print(\"Examples formatted for prompt\")\n",
    "print(f\"Formatted examples length: {len(formatted_examples)} characters\")\n",
    "print(f\"\\nSample formatted examples:\")\n",
    "print(formatted_examples[:300] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02c25d61-5a3d-4148-b670-02118ac780ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic prompt template created\n",
      "Template length: 2137 characters\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def create_prompt_with_examples(formatted_examples):\n",
    "    \"\"\"Create prompt template with dynamic examples\"\"\"\n",
    "    \n",
    "    template = f\"\"\"You are an expert OpenStack log analyst. Classify the following log message into one of these categories:\n",
    "\n",
    "CATEGORIES:\n",
    "1. System_Operations - LibVirt driver operations, system-level tasks\n",
    "2. Instance_Management - VM lifecycle, instance operations  \n",
    "3. Network_Operations - VIF operations, network connectivity\n",
    "4. Resource_Management - Compute claims, resource allocation\n",
    "5. Scheduler_Operations - Nova scheduler activities, allocation reports\n",
    "6. Error_Handling - Error conditions, failures, exceptions\n",
    "\n",
    "REAL EXAMPLES FROM YOUR DATASET:\n",
    "{formatted_examples}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Analyze the log message components (service, action, context)\n",
    "- Consider the technical operation being performed\n",
    "- Focus on the primary purpose/function\n",
    "- Provide confidence between 0.0 and 1.0\n",
    "\n",
    "LOG MESSAGE: {{log_message}}\n",
    "\n",
    "Respond in valid JSON format:\n",
    "{{{{\n",
    "  \"category\": \"category_name\",\n",
    "  \"confidence\": 0.85,\n",
    "  \"reasoning\": \"brief explanation\"\n",
    "}}}}\"\"\"\n",
    "    \n",
    "    return template\n",
    "\n",
    "# Create dynamic template\n",
    "dynamic_template = create_prompt_with_examples(formatted_examples)\n",
    "\n",
    "# Create LangChain PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"log_message\"],\n",
    "    template=dynamic_template\n",
    ")\n",
    "\n",
    "print(\"Dynamic prompt template created\")\n",
    "print(f\"Template length: {len(dynamic_template)} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d428562c-d330-455c-8870-913783799439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['log_message'] input_types={} partial_variables={} template='You are an expert OpenStack log analyst. Classify the following log message into one of these categories:\\n\\nCATEGORIES:\\n1. System_Operations - LibVirt driver operations, system-level tasks\\n2. Instance_Management - VM lifecycle, instance operations  \\n3. Network_Operations - VIF operations, network connectivity\\n4. Resource_Management - Compute claims, resource allocation\\n5. Scheduler_Operations - Nova scheduler activities, allocation reports\\n6. Error_Handling - Error conditions, failures, exceptions\\n\\nREAL EXAMPLES FROM YOUR DATASET:\\nSystem_Operations: \"INFO nova.virt.libvirt.driver [req-c081868d-4495-4a56-adaa-349c1e09b072] [instance: 56b8e26a-1ce7-460d-a6e5-d60f2ffbf7fc...\"\\nSystem_Operations: \"INFO nova.virt.libvirt.driver [req-3a04b6a9-5a46-409e-ab95-cfbea20059aa] [instance: ba40f9c5-a0d8-4922-9e3a-8d4904ce797c...\"\\nInstance_Management: \"INFO nova.compute.manager [None req-77b899cc-1990-4518-8ca6-4ab2c2ace9aa None None] [instance: 7b61ba1b-9854-466d-abcf-9...\"\\nInstance_Management: \"INFO nova.compute.manager [None req-0f3e0c2b-b117-4591-87f4-2bc42e80139b admin admin] [instance: c6ed97cd-b231-4c1f-8152...\"\\nNetwork_Operations: \"INFO os_vif [req-2b352c90-31b9-440d-8dfd-83a797a95e41] Successfully plugged vif VIFOpenVSwitch\"\\nNetwork_Operations: \"INFO os_vif [req-a710ec75-2c50-43f0-aa24-984c5936a6af] Successfully plugged vif VIFOpenVSwitch\"\\nResource_Management: \"INFO nova.compute.claims [req-jkl] Claim successful\"\\nScheduler_Operations: \"ERROR nova.compute.manager [instance: 80cd044d-b8f2-4dab-b6b3-1e95b6e1355d]     raise self.value\"\\nScheduler_Operations: \"INFO nova.scheduler.client.report [None req-1f96901e-3090-48a1-a050-9e3e1ebe6137 admin admin] Deleted allocation for ins...\"\\nError_Handling: \"ERROR nova.compute.manager [instance: xyz] File not found\"\\n\\nINSTRUCTIONS:\\n- Analyze the log message components (service, action, context)\\n- Consider the technical operation being performed\\n- Focus on the primary purpose/function\\n- Provide confidence between 0.0 and 1.0\\n\\nLOG MESSAGE: {log_message}\\n\\nRespond in valid JSON format:\\n{{\\n  \"category\": \"category_name\",\\n  \"confidence\": 0.85,\\n  \"reasoning\": \"brief explanation\"\\n}}'\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "454329d0-d927-4e52-9d30-8974a9e7128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template test completed\n",
      "Formatted prompt preview:\n",
      "You are an expert OpenStack log analyst. Classify the following log message into one of these categories:\n",
      "\n",
      "CATEGORIES:\n",
      "1. System_Operations - LibVirt driver operations, system-level tasks\n",
      "2. Instance_Management - VM lifecycle, instance operations  \n",
      "3. Network_Operations - VIF operations, network connectivity\n",
      "4. Resource_Management - Compute claims, resource allocation\n",
      "5. Scheduler_Operations - Nov...\n",
      "\n",
      "Prompt stats:\n",
      "  Total length: 2194 characters\n",
      "  Contains examples: True\n",
      "  Contains categories: True\n"
     ]
    }
   ],
   "source": [
    "# Test the dynamic template\n",
    "test_log = \"INFO nova.compute.manager [req-test] [instance: test-id] Testing message\"\n",
    "\n",
    "# Format the prompt\n",
    "formatted_prompt = prompt.format(log_message=test_log)\n",
    "\n",
    "print(\"Template test completed\")\n",
    "print(f\"Formatted prompt preview:\")\n",
    "print(formatted_prompt[:400] + \"...\")\n",
    "print(f\"\\nPrompt stats:\")\n",
    "print(f\"  Total length: {len(formatted_prompt)} characters\")\n",
    "print(f\"  Contains examples: {'REAL EXAMPLES' in formatted_prompt}\")\n",
    "print(f\"  Contains categories: {'CATEGORIES:' in formatted_prompt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c3c7d7-e8d2-4642-a0af-57b2775e7423",
   "metadata": {},
   "source": [
    "# Create Pydantic Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "179a0e72-6461-4ca2-838d-da1279591de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic classification function created\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "def classify_log_with_pydantic(log_message: str, llm, prompt_template) -> LogClassification:\n",
    "    \"\"\"Classify a single log using LangChain with Pydantic output\"\"\"\n",
    "    try:\n",
    "        # Format the prompt\n",
    "        formatted_prompt = prompt_template.format(log_message=log_message)\n",
    "        \n",
    "        # Create message\n",
    "        messages = [HumanMessage(content=formatted_prompt)]\n",
    "        \n",
    "        # Get response from LLM\n",
    "        response = llm.invoke(messages)\n",
    "        response_text = response.content.strip()\n",
    "        \n",
    "        print(f\"Raw LLM response: {response_text[:100]}...\")\n",
    "        \n",
    "        return response_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM call: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Basic classification function created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8392ea47-b630-47a7-836a-fda830494127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct JSON parsing successful\n",
      "Test parsing result: {'category': 'System_Operations', 'confidence': 0.85, 'reasoning': 'Test'}\n"
     ]
    }
   ],
   "source": [
    "def parse_llm_response(response_text: str) -> dict:\n",
    "    \"\"\"Parse LLM response to extract JSON\"\"\"\n",
    "    try:\n",
    "        # Try direct JSON parsing\n",
    "        result = json.loads(response_text)\n",
    "        print(\"Direct JSON parsing successful\")\n",
    "        return result\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        # Try to extract JSON from response\n",
    "        import re\n",
    "        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            json_str = json_match.group()\n",
    "            try:\n",
    "                result = json.loads(json_str)\n",
    "                print(\"Extracted JSON parsing successful\")\n",
    "                return result\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Extracted JSON parsing failed\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"No JSON found in response\")\n",
    "            return None\n",
    "\n",
    "# Test JSON parsing\n",
    "test_json = '{\"category\": \"System_Operations\", \"confidence\": 0.85, \"reasoning\": \"Test\"}'\n",
    "parsed = parse_llm_response(test_json)\n",
    "print(f\"Test parsing result: {parsed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e41a9b53-2954-4a54-8637-2d3d4305612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pydantic object created: System_Operations\n",
      "Test Pydantic object: category='System_Operations' confidence=0.85 reasoning='Test reasoning'\n"
     ]
    }
   ],
   "source": [
    "def create_pydantic_result(json_data: dict) -> LogClassification:\n",
    "    \"\"\"Create Pydantic object from JSON data\"\"\"\n",
    "    try:\n",
    "        # Validate required fields\n",
    "        required_fields = ['category', 'confidence', 'reasoning']\n",
    "        if not all(field in json_data for field in required_fields):\n",
    "            missing = [f for f in required_fields if f not in json_data]\n",
    "            raise ValueError(f\"Missing fields: {missing}\")\n",
    "        \n",
    "        # Create Pydantic object\n",
    "        result = LogClassification(**json_data)\n",
    "        print(f\"Pydantic object created: {result.category}\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Pydantic creation failed: {e}\")\n",
    "        # Return default object\n",
    "        return LogClassification(\n",
    "            category=\"Unknown\",\n",
    "            confidence=0.0,\n",
    "            reasoning=f\"Pydantic error: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Test Pydantic creation\n",
    "test_data = {\"category\": \"System_Operations\", \"confidence\": 0.85, \"reasoning\": \"Test reasoning\"}\n",
    "pydantic_obj = create_pydantic_result(test_data)\n",
    "print(f\"Test Pydantic object: {pydantic_obj}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14950928-6c06-4ca5-b842-ed77a563a434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete classification function created\n"
     ]
    }
   ],
   "source": [
    "def classify_single_log_complete(log_message: str, llm, prompt_template) -> LogClassification:\n",
    "    \"\"\"Complete classification function with all steps\"\"\"\n",
    "    \n",
    "    # Step 1: Get LLM response\n",
    "    response_text = classify_log_with_pydantic(log_message, llm, prompt_template)\n",
    "    if response_text is None:\n",
    "        return LogClassification(\n",
    "            category=\"Error\",\n",
    "            confidence=0.0,\n",
    "            reasoning=\"LLM call failed\"\n",
    "        )\n",
    "    \n",
    "    # Step 2: Parse JSON\n",
    "    json_data = parse_llm_response(response_text)\n",
    "    if json_data is None:\n",
    "        return LogClassification(\n",
    "            category=\"Unknown\",\n",
    "            confidence=0.0,\n",
    "            reasoning=\"JSON parsing failed\"\n",
    "        )\n",
    "    \n",
    "    # Step 3: Create Pydantic object\n",
    "    result = create_pydantic_result(json_data)\n",
    "    return result\n",
    "\n",
    "print(\"Complete classification function created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "28b6a4c7-3a63-4cd2-8fac-62e4a25abf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing complete function with log:\n",
      "   WARNING oslo.service.loopingcall [-] Function 'nova.virt.libvirt.driver.LibvirtD...\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message indi...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "\n",
      "Complete test result:\n",
      "   Category: Error_Handling\n",
      "   Confidence: 0.85\n",
      "   Reasoning: The log message indicates a warning about a function ('_wait_for_boot') taking longer than expected, which suggests an error or unexpected condition occurred during the boot process of a VM, managed by the Libvirt driver.\n",
      "   Type: <class '__main__.LogClassification'>\n"
     ]
    }
   ],
   "source": [
    "# Test with a real log\n",
    "test_log = unclassified_logs.iloc[0]['raw_log_text']\n",
    "print(f\"Testing complete function with log:\")\n",
    "print(f\"   {test_log[:80]}...\")\n",
    "\n",
    "# Run complete classification\n",
    "result = classify_single_log_complete(test_log, llm, prompt)\n",
    "\n",
    "print(f\"\\nComplete test result:\")\n",
    "print(f\"   Category: {result.category}\")\n",
    "print(f\"   Confidence: {result.confidence}\")\n",
    "print(f\"   Reasoning: {result.reasoning}\")\n",
    "print(f\"   Type: {type(result)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c5b30-dc37-43b4-80c0-153522d584bf",
   "metadata": {},
   "source": [
    "# Create Batch Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f908af53-2a6c-4fc4-b685-c11bd42a5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing function created\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def process_batch_of_logs(logs_batch, llm, prompt_template, delay=0.1):\n",
    "    \"\"\"Process a small batch of logs\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Processing batch of {len(logs_batch)} logs...\")\n",
    "    \n",
    "    for idx, log_message in enumerate(logs_batch):\n",
    "        print(f\"  Log {idx+1}/{len(logs_batch)}\", end='\\r')\n",
    "        \n",
    "        # Classify single log\n",
    "        result = classify_single_log_complete(log_message, llm, prompt_template)\n",
    "        results.append(result)\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    print(f\"\\nBatch processing completed!\")\n",
    "    return results\n",
    "\n",
    "print(\"Batch processing function created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0bbe6a23-9bed-46fe-bda4-fe74046a2bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch processing with 3 logs...\n",
      "This will take about 30-60 seconds...\n",
      "Processing batch of 3 logs...\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message indi...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message conta...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The log message does not ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "\n",
      "Batch processing completed!\n",
      "\n",
      "Batch results summary:\n",
      "  1. Error_Handling (conf: 0.85)\n",
      "  2. Error_Handling (conf: 0.9)\n",
      "  3. Error_Handling (conf: 0.6)\n"
     ]
    }
   ],
   "source": [
    "# Test with 3 logs first\n",
    "test_batch_size = 3\n",
    "test_logs_batch = unclassified_logs.head(test_batch_size)['raw_log_text'].tolist()\n",
    "\n",
    "print(f\"Testing batch processing with {test_batch_size} logs...\")\n",
    "print(\"This will take about 30-60 seconds...\")\n",
    "\n",
    "# Process small test batch\n",
    "batch_results = process_batch_of_logs(\n",
    "    test_logs_batch, \n",
    "    llm, \n",
    "    prompt,\n",
    "    delay=0.2  # Slower for testing\n",
    ")\n",
    "\n",
    "print(f\"\\nBatch results summary:\")\n",
    "for i, result in enumerate(batch_results):\n",
    "    print(f\"  {i+1}. {result.category} (conf: {result.confidence})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dff06caa-a278-4dc6-a447-446a2c2de7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results converted to DataFrame\n",
      "Results DataFrame shape: (3, 4)\n",
      "\n",
      "Sample results:\n",
      "     llm_category  llm_confidence\n",
      "0  Error_Handling            0.85\n",
      "1  Error_Handling            0.90\n",
      "2  Error_Handling            0.60\n"
     ]
    }
   ],
   "source": [
    "def results_to_dataframe(results, original_indices):\n",
    "    \"\"\"Convert Pydantic results to DataFrame\"\"\"\n",
    "    \n",
    "    data = []\n",
    "    for i, result in enumerate(results):\n",
    "        data.append({\n",
    "            'original_index': original_indices[i],\n",
    "            'llm_category': result.category,\n",
    "            'llm_confidence': result.confidence,\n",
    "            'llm_reasoning': result.reasoning\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Convert test results\n",
    "test_indices = unclassified_logs.head(test_batch_size).index.tolist()\n",
    "results_df = results_to_dataframe(batch_results, test_indices)\n",
    "\n",
    "print(\"Results converted to DataFrame\")\n",
    "print(f\"Results DataFrame shape: {results_df.shape}\")\n",
    "print(f\"\\nSample results:\")\n",
    "print(results_df[['llm_category', 'llm_confidence']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb6c5f35-9d88-4fe2-ae7c-463606082817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Analysis:\n",
      "  Total processed: 3\n",
      "\n",
      "Categories found:\n",
      "  Error_Handling: 3\n",
      "\n",
      "Confidence stats:\n",
      "  Average: 0.783\n",
      "  High confidence (≥0.7): 2/3\n",
      "\n",
      "Sample reasoning:\n",
      "  1. The log message indicates a warning about a function ('_wait...\n",
      "  2. The log message contains an ERROR level notification from no...\n"
     ]
    }
   ],
   "source": [
    "def analyze_batch_results(results):\n",
    "    \"\"\"Analyze batch classification results\"\"\"\n",
    "    \n",
    "    categories = [r.category for r in results]\n",
    "    confidences = [r.confidence for r in results]\n",
    "    \n",
    "    print(f\"Batch Analysis:\")\n",
    "    print(f\"  Total processed: {len(results)}\")\n",
    "    \n",
    "    # Category distribution\n",
    "    from collections import Counter\n",
    "    category_counts = Counter(categories)\n",
    "    print(f\"\\nCategories found:\")\n",
    "    for category, count in category_counts.items():\n",
    "        print(f\"  {category}: {count}\")\n",
    "    \n",
    "    # Confidence stats\n",
    "    if confidences:\n",
    "        avg_conf = sum(confidences) / len(confidences)\n",
    "        high_conf = len([c for c in confidences if c >= 0.7])\n",
    "        print(f\"\\nConfidence stats:\")\n",
    "        print(f\"  Average: {avg_conf:.3f}\")\n",
    "        print(f\"  High confidence (≥0.7): {high_conf}/{len(confidences)}\")\n",
    "    \n",
    "    # Show sample reasoning\n",
    "    print(f\"\\nSample reasoning:\")\n",
    "    for i, result in enumerate(results[:2]):\n",
    "        print(f\"  {i+1}. {result.reasoning[:60]}...\")\n",
    "\n",
    "# Analyze test batch\n",
    "analyze_batch_results(batch_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a7351-36f2-41f6-8184-ffc2ae07bc3c",
   "metadata": {},
   "source": [
    "# Apply Confidence Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40b56368-9249-4d29-91bb-2ed854d80947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence filtering (threshold: 0.7):\n",
      "  High confidence: 2\n",
      "  Low confidence: 1\n",
      "\n",
      "High confidence results:\n",
      "     llm_category  llm_confidence\n",
      "0  Error_Handling            0.85\n",
      "1  Error_Handling            0.90\n",
      "\n",
      "⚠️  Low confidence results:\n",
      "     llm_category  llm_confidence\n",
      "2  Error_Handling             0.6\n"
     ]
    }
   ],
   "source": [
    "def filter_by_confidence(results_df, confidence_threshold=0.7):\n",
    "    \"\"\"Filter results by confidence threshold\"\"\"\n",
    "    \n",
    "    high_confidence = results_df[results_df['llm_confidence'] >= confidence_threshold]\n",
    "    low_confidence = results_df[results_df['llm_confidence'] < confidence_threshold]\n",
    "    \n",
    "    print(f\"Confidence filtering (threshold: {confidence_threshold}):\")\n",
    "    print(f\"  High confidence: {len(high_confidence)}\")\n",
    "    print(f\"  Low confidence: {len(low_confidence)}\")\n",
    "    \n",
    "    return high_confidence, low_confidence\n",
    "\n",
    "# Apply confidence filtering to test results\n",
    "high_conf_results, low_conf_results = filter_by_confidence(results_df, confidence_threshold=0.7)\n",
    "\n",
    "print(f\"\\nHigh confidence results:\")\n",
    "print(high_conf_results[['llm_category', 'llm_confidence']])\n",
    "\n",
    "if len(low_conf_results) > 0:\n",
    "    print(f\"\\n⚠️  Low confidence results:\")\n",
    "    print(low_conf_results[['llm_category', 'llm_confidence']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10c9668b-5f51-4022-a924-8d79fca08119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing larger batch of 20 logs...\n",
      "This will take about 3-5 minutes...\n",
      "⏳ Please wait...\n",
      "Processing batch of 20 logs...\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message indi...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.95,\n",
      "  \"reasoning\": \"The log message cont...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The log message does not ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message conta...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.95,\n",
      "  \"reasoning\": \"The log message cont...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.2,\n",
      "  \"reasoning\": \"The log message does not ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.95,\n",
      "  \"reasoning\": \"The log message cont...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message conta...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message indic...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message conta...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.2,\n",
      "  \"reasoning\": \"The log message does not ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message conta...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message conta...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message is ca...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The log message does ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.95,\n",
      "  \"reasoning\": \"The log message cont...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.95,\n",
      "  \"reasoning\": \"The log message cont...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Error_Handling\",\n",
      "  \"confidence\": 0.95,\n",
      "  \"reasoning\": \"The log message cont...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Error_Handling\n",
      "\n",
      "Batch processing completed!\n",
      "\n",
      "Larger batch completed!\n",
      "Processed 20 logs\n"
     ]
    }
   ],
   "source": [
    "# Process a larger batch (20 logs)\n",
    "larger_batch_size = 20\n",
    "larger_test_logs = unclassified_logs.head(larger_batch_size)['raw_log_text'].tolist()\n",
    "\n",
    "print(f\"Processing larger batch of {larger_batch_size} logs...\")\n",
    "print(\"This will take about 3-5 minutes...\")\n",
    "print(\"⏳ Please wait...\")\n",
    "\n",
    "# Process larger batch\n",
    "larger_batch_results = process_batch_of_logs(\n",
    "    larger_test_logs, \n",
    "    llm, \n",
    "    prompt,\n",
    "    delay=0.15  # Slightly faster\n",
    ")\n",
    "\n",
    "print(f\"\\nLarger batch completed!\")\n",
    "print(f\"Processed {len(larger_batch_results)} logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efe040d0-6769-4dff-95dc-61691a820d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Analysis:\n",
      "  Total processed: 20\n",
      "\n",
      "Categories found:\n",
      "  Error_Handling: 18\n",
      "  Resource_Management: 2\n",
      "\n",
      "Confidence stats:\n",
      "  Average: 0.812\n",
      "  High confidence (≥0.7): 16/20\n",
      "\n",
      "Sample reasoning:\n",
      "  1. The log message indicates a warning about a function ('_wait...\n",
      "  2. The log message contains an 'ERROR' level notification from ...\n",
      "Confidence filtering (threshold: 0.7):\n",
      "  High confidence: 16\n",
      "  Low confidence: 4\n",
      "\n",
      "Larger batch summary:\n",
      "  Total processed: 20\n",
      "  High confidence: 16 (80.0%)\n",
      "  Low confidence: 4 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze larger batch results\n",
    "analyze_batch_results(larger_batch_results)\n",
    "\n",
    "# Convert to DataFrame\n",
    "larger_indices = unclassified_logs.head(larger_batch_size).index.tolist()\n",
    "larger_results_df = results_to_dataframe(larger_batch_results, larger_indices)\n",
    "\n",
    "# Apply confidence filtering\n",
    "high_conf_larger, low_conf_larger = filter_by_confidence(larger_results_df, confidence_threshold=0.7)\n",
    "\n",
    "print(f\"\\nLarger batch summary:\")\n",
    "print(f\"  Total processed: {len(larger_results_df)}\")\n",
    "print(f\"  High confidence: {len(high_conf_larger)} ({len(high_conf_larger)/len(larger_results_df)*100:.1f}%)\")\n",
    "print(f\"  Low confidence: {len(low_conf_larger)} ({len(low_conf_larger)/len(larger_results_df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "276f8fed-caa3-4a9d-b996-603763b12f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset processing estimates:\n",
      "  Total unclassified logs: 14,972\n",
      "  Estimated time: 87.3 minutes (1.5 hours)\n",
      "  Estimated API calls: 14,972\n",
      "\n",
      "Estimated final results:\n",
      "  High confidence classifications: 11,977\n",
      "  Low confidence (manual review): 2,995\n",
      "\n",
      "Complete pipeline estimate:\n",
      "  Regex classified: 36,537 (59.0%)\n",
      "  BERT classified: 14,166 (22.9%)\n",
      "  LLM classified: 11,977 (19.3%)\n",
      "  Manual review: 2,995 (4.8%)\n",
      "  Total automated: 62,680 (101.2%)\n"
     ]
    }
   ],
   "source": [
    "# Estimate time and cost for full dataset\n",
    "total_unclassified = len(unclassified_logs)\n",
    "avg_time_per_log = 0.15 + 0.2  # delay + processing time\n",
    "estimated_time_minutes = (total_unclassified * avg_time_per_log) / 60\n",
    "\n",
    "print(f\"Full dataset processing estimates:\")\n",
    "print(f\"  Total unclassified logs: {total_unclassified:,}\")\n",
    "print(f\"  Estimated time: {estimated_time_minutes:.1f} minutes ({estimated_time_minutes/60:.1f} hours)\")\n",
    "print(f\"  Estimated API calls: {total_unclassified:,}\")\n",
    "\n",
    "# Based on larger batch performance\n",
    "if len(larger_batch_results) > 0:\n",
    "    high_conf_rate = len(high_conf_larger) / len(larger_results_df)\n",
    "    estimated_high_conf = int(total_unclassified * high_conf_rate)\n",
    "    estimated_low_conf = total_unclassified - estimated_high_conf\n",
    "    \n",
    "    print(f\"\\nEstimated final results:\")\n",
    "    print(f\"  High confidence classifications: {estimated_high_conf:,}\")\n",
    "    print(f\"  Low confidence (manual review): {estimated_low_conf:,}\")\n",
    "    \n",
    "    # Final pipeline estimate\n",
    "    regex_count = df['regex_label'].notnull().sum()\n",
    "    bert_count = df['bert_label'].notnull().sum()\n",
    "    \n",
    "    print(f\"\\nComplete pipeline estimate:\")\n",
    "    print(f\"  Regex classified: {regex_count:,} ({regex_count/len(df)*100:.1f}%)\")\n",
    "    print(f\"  BERT classified: {bert_count:,} ({bert_count/len(df)*100:.1f}%)\")\n",
    "    print(f\"  LLM classified: {estimated_high_conf:,} ({estimated_high_conf/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Manual review: {estimated_low_conf:,} ({estimated_low_conf/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    total_automated = regex_count + bert_count + estimated_high_conf\n",
    "    print(f\"  Total automated: {total_automated:,} ({total_automated/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dde6c2-f8d3-43bd-aa51-d189e64babaf",
   "metadata": {},
   "source": [
    "# Create Error Subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1264fe80-05aa-4797-9356-6fca33f8bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced categories with error subcategories defined\n",
      "Total categories: 11\n",
      "  System_Operations: LibVirt driver operations, system-level tasks\n",
      "  Instance_Management: VM lifecycle, instance operations\n",
      "  Network_Operations: VIF operations, network connectivity\n",
      "  Resource_Management: Compute claims, resource allocation\n",
      "  Scheduler_Operations: Nova scheduler activities, allocation reports\n",
      "  Boot_Timeout_Errors: VM boot timeouts, startup failures\n",
      "  Network_Connection_Errors: VIF connection failures, network issues\n",
      "  Resource_Allocation_Errors: Memory/CPU allocation failures, resource exhaustion\n",
      "  File_System_Errors: File not found, permission errors, I/O failures\n",
      "  Configuration_Errors: Invalid config, missing parameters, setup issues\n",
      "  Service_Communication_Errors: API timeouts, service unavailable, connection refused\n"
     ]
    }
   ],
   "source": [
    "# Enhanced categories with error subcategories\n",
    "ENHANCED_CATEGORIES = {\n",
    "    # System Operations\n",
    "    'System_Operations': 'LibVirt driver operations, system-level tasks',\n",
    "    'Instance_Management': 'VM lifecycle, instance operations',\n",
    "    'Network_Operations': 'VIF operations, network connectivity', \n",
    "    'Resource_Management': 'Compute claims, resource allocation',\n",
    "    'Scheduler_Operations': 'Nova scheduler activities, allocation reports',\n",
    "    \n",
    "    # Error Subcategories (instead of generic Error_Handling)\n",
    "    'Boot_Timeout_Errors': 'VM boot timeouts, startup failures',\n",
    "    'Network_Connection_Errors': 'VIF connection failures, network issues',\n",
    "    'Resource_Allocation_Errors': 'Memory/CPU allocation failures, resource exhaustion',\n",
    "    'File_System_Errors': 'File not found, permission errors, I/O failures',\n",
    "    'Configuration_Errors': 'Invalid config, missing parameters, setup issues',\n",
    "    'Service_Communication_Errors': 'API timeouts, service unavailable, connection refused'\n",
    "}\n",
    "\n",
    "print(\"Enhanced categories with error subcategories defined\")\n",
    "print(f\"Total categories: {len(ENHANCED_CATEGORIES)}\")\n",
    "for category, description in ENHANCED_CATEGORIES.items():\n",
    "    print(f\"  {category}: {description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14222368-9089-4b9b-ab30-c725d0e37a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error subcategory prompt created\n"
     ]
    }
   ],
   "source": [
    "def create_error_subcategory_prompt(formatted_examples):\n",
    "    \"\"\"Create prompt with specific error subcategories\"\"\"\n",
    "    \n",
    "    subcategory_template = f\"\"\"You are an expert OpenStack log analyst. Classify the following log message into the MOST SPECIFIC category that matches the error type or operation.\n",
    "\n",
    "CATEGORIES:\n",
    "\n",
    "SYSTEM OPERATIONS:\n",
    "1. System_Operations - LibVirt driver operations, system-level tasks\n",
    "2. Instance_Management - VM lifecycle (start/stop/pause), instance state changes  \n",
    "3. Network_Operations - VIF operations, network setup/teardown\n",
    "4. Resource_Management - Compute claims, resource allocation\n",
    "5. Scheduler_Operations - Nova scheduler activities, placement decisions\n",
    "\n",
    "ERROR SUBCATEGORIES (Be Specific!):\n",
    "6. Boot_Timeout_Errors - VM boot timeouts, startup failures, \"_wait_for_boot\" issues\n",
    "7. Network_Connection_Errors - VIF connection failures, network setup issues\n",
    "8. Resource_Allocation_Errors - Memory/CPU allocation failures, resource exhaustion\n",
    "9. File_System_Errors - File not found, permission errors, I/O failures  \n",
    "10. Configuration_Errors - Invalid config, missing parameters, setup issues\n",
    "11. Service_Communication_Errors - API timeouts, service unavailable, connection refused\n",
    "\n",
    "CLASSIFICATION RULES:\n",
    "- For WARNING/ERROR logs: Choose the MOST SPECIFIC error subcategory\n",
    "- For INFO logs: Choose the appropriate system operation category\n",
    "- Look for keywords: \"timeout\" → Boot_Timeout_Errors, \"file\" → File_System_Errors\n",
    "- Focus on the ROOT CAUSE, not just that it's an error\n",
    "\n",
    "REAL EXAMPLES:\n",
    "{formatted_examples}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Read the ENTIRE log message\n",
    "- Identify the specific type of error or operation\n",
    "- Choose the MOST SPECIFIC category that fits\n",
    "- Provide confidence 0.6-1.0 (be realistic)\n",
    "\n",
    "LOG MESSAGE: {{log_message}}\n",
    "\n",
    "Respond in JSON format:\n",
    "{{{{\n",
    "  \"category\": \"specific_category_name\",\n",
    "  \"confidence\": 0.85,\n",
    "  \"reasoning\": \"explanation focusing on why this specific subcategory\"\n",
    "}}}}\"\"\"\n",
    "    \n",
    "    return subcategory_template\n",
    "\n",
    "# Create enhanced prompt\n",
    "enhanced_examples = format_examples_for_prompt(selected_examples)\n",
    "subcategory_prompt_template = create_error_subcategory_prompt(enhanced_examples)\n",
    "subcategory_prompt = PromptTemplate(\n",
    "    input_variables=[\"log_message\"],\n",
    "    template=subcategory_prompt_template\n",
    ")\n",
    "\n",
    "print(\"Error subcategory prompt created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1b24071-07fb-427d-9566-da57a755bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing error subcategory classification with 10 logs...\n",
      "Processing batch of 10 logs...\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Boot_Timeout_Errors\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Boot_Timeout_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Service_Communication_Errors\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log mes...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Service_Communication_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"System_Operations\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The log message provid...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: System_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Service_Communication_Errors\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Service_Communication_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Allocation_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Allocation_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"System_Operations\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The provided log messa...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: System_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Instance_Management\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message is ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Instance_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Connection_Errors\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log me...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Connection_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "\n",
      "Batch processing completed!\n",
      "\n",
      "Subcategory results:\n",
      "  Boot_Timeout_Errors: 1 (10.0%)\n",
      "  Service_Communication_Errors: 2 (20.0%)\n",
      "  System_Operations: 2 (20.0%)\n",
      "  Resource_Allocation_Errors: 1 (10.0%)\n",
      "  File_System_Errors: 2 (20.0%)\n",
      "  Instance_Management: 1 (10.0%)\n",
      "  Network_Connection_Errors: 1 (10.0%)\n",
      "\n",
      "Sample subcategory classifications:\n",
      "  1. Boot_Timeout_Errors (conf: 0.9)\n",
      "     Reasoning: The log message indicates a warning about the '_wait_for_boot' function running ...\n",
      "  2. Service_Communication_Errors (conf: 0.8)\n",
      "     Reasoning: The log message indicates an error in the nova.compute.manager, but it does not ...\n",
      "  3. System_Operations (conf: 0.6)\n",
      "     Reasoning: The log message provided does not contain enough information to classify it into...\n"
     ]
    }
   ],
   "source": [
    "# Test with your existing logs to see subcategory distribution\n",
    "test_subcategory_size = 10\n",
    "test_subcategory_logs = unclassified_logs.head(test_subcategory_size)['raw_log_text'].tolist()\n",
    "\n",
    "print(f\"Testing error subcategory classification with {test_subcategory_size} logs...\")\n",
    "\n",
    "# Process with subcategory prompt\n",
    "subcategory_results = process_batch_of_logs(\n",
    "    test_subcategory_logs, \n",
    "    llm, \n",
    "    subcategory_prompt,\n",
    "    delay=0.15\n",
    ")\n",
    "\n",
    "print(f\"\\nSubcategory results:\")\n",
    "categories = [r.category for r in subcategory_results]\n",
    "from collections import Counter\n",
    "subcategory_dist = Counter(categories)\n",
    "\n",
    "for category, count in subcategory_dist.items():\n",
    "    print(f\"  {category}: {count} ({count/len(subcategory_results)*100:.1f}%)\")\n",
    "\n",
    "# Show sample classifications\n",
    "print(f\"\\nSample subcategory classifications:\")\n",
    "for i, result in enumerate(subcategory_results[:3]):\n",
    "    print(f\"  {i+1}. {result.category} (conf: {result.confidence})\")\n",
    "    print(f\"     Reasoning: {result.reasoning[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0718069b-d2b6-4082-be20-fe26216fecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Distribution Comparison:\n",
      "\n",
      "🔴 BEFORE (Generic Error_Handling):\n",
      "  Error_Handling: 18/20 (90%)\n",
      "  Resource_Management: 2/20 (10%)\n",
      "  Other categories: 0/20 (0%)\n",
      "\n",
      "🟢 AFTER (Error Subcategories):\n",
      "  Boot_Timeout_Errors: 1/10 (10.0%)\n",
      "  Service_Communication_Errors: 2/10 (20.0%)\n",
      "  System_Operations: 2/10 (20.0%)\n",
      "  Resource_Allocation_Errors: 1/10 (10.0%)\n",
      "  File_System_Errors: 2/10 (20.0%)\n",
      "  Instance_Management: 1/10 (10.0%)\n",
      "  Network_Connection_Errors: 1/10 (10.0%)\n",
      "\n",
      "Improvement Metrics:\n",
      "  Category diversity: +250% (2 → 7 categories)\n",
      "  Specificity: Much higher (specific error types vs generic 'error')\n",
      "  Actionability: Better (teams know exact error type)\n"
     ]
    }
   ],
   "source": [
    "# Compare the distribution improvement\n",
    "print(f\"Classification Distribution Comparison:\")\n",
    "print(f\"\\n🔴 BEFORE (Generic Error_Handling):\")\n",
    "print(f\"  Error_Handling: 18/20 (90%)\")\n",
    "print(f\"  Resource_Management: 2/20 (10%)\")\n",
    "print(f\"  Other categories: 0/20 (0%)\")\n",
    "\n",
    "print(f\"\\n🟢 AFTER (Error Subcategories):\")\n",
    "for category, count in subcategory_dist.items():\n",
    "    print(f\"  {category}: {count}/{len(subcategory_results)} ({count/len(subcategory_results)*100:.1f}%)\")\n",
    "\n",
    "# Calculate diversity improvement\n",
    "before_categories = 2  # Only Error_Handling + Resource_Management\n",
    "after_categories = len(subcategory_dist)\n",
    "diversity_improvement = (after_categories - before_categories) / before_categories * 100\n",
    "\n",
    "print(f\"\\nImprovement Metrics:\")\n",
    "print(f\"  Category diversity: +{diversity_improvement:.0f}% ({before_categories} → {after_categories} categories)\")\n",
    "print(f\"  Specificity: Much higher (specific error types vs generic 'error')\")\n",
    "print(f\"  Actionability: Better (teams know exact error type)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baabb9bf-ad43-4577-b277-f7a2a9607f91",
   "metadata": {},
   "source": [
    "# Scale to Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad993ec8-e61f-475d-b2d1-35de8fe7e7a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing large sample of 500 logs with error subcategories...\n",
      "⏳ This will take about 15-20 minutes...\n",
      "This will give us reliable distribution statistics\n",
      "Processing batch of 500 logs...\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Boot_Timeout_Errors\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Boot_Timeout_Errors\n",
      "Raw LLM response: {\n",
      "  \"category\": \"Service_Communication_Errors\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log message...\n",
      "Direct JSON parsing successful\n",
      "Pydantic object created: Service_Communication_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"System_Operations\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The log message provid...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: System_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Service_Communication_Errors\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Service_Communication_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Boot_Timeout_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Boot_Timeout_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"System_Operations\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The log message does n...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: System_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Scheduler_Operations\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log message is ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Scheduler_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Connection_Errors\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log me...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Connection_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"System_Operations\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The log message does n...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: System_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: {\n",
      "  \"category\": \"Configuration_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message indica...\n",
      "Direct JSON parsing successful\n",
      "Pydantic object created: Configuration_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Configuration_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log messag...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Configuration_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Connection_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log m...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Connection_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"System_Operations\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The log message provid...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: System_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Service_Communication_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log me...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Service_Communication_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Connection_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log m...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Connection_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Allocation_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Allocation_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message i...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message i...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Boot_Timeout_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Boot_Timeout_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log message conta...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Instance_Management\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Instance_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Instance_Management\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Instance_Management\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log message conta...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Instance_Management\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log message cont...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Instance_Management\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ment...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Service_Communication_Errors\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Service_Communication_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Connection_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log m...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Connection_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Connection_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log m...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Connection_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message i...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log message conta...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Service_Communication_Errors\",\n",
      "  \"confidence\": 0.7,\n",
      "  \"reasoning\": \"The log mes...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Service_Communication_Errors\n",
      "Raw LLM response: {\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message indicates...\n",
      "Direct JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: {\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message contains...\n",
      "Extracted JSON parsing failed\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Connection_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log m...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Connection_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Service_Communication_Errors\",\n",
      "  \"confidence\": 0.7,\n",
      "  \"reasoning\": \"The log...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Service_Communication_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message i...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing failed\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing failed\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message m...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Operations\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Operations\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"Service_Communication_Errors\",\n",
      "  \"confidence\": 0.8,\n",
      "  \"reasoning\": \"The log mes...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Service_Communication_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message m...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Network_Connection_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log m...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Network_Connection_Errors\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Configuration_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log messag...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Configuration_Errors\n",
      "Raw LLM response: ```\n",
      "{\n",
      "  \"category\": \"System_Operations\",\n",
      "  \"confidence\": 0.6,\n",
      "  \"reasoning\": \"The provided log messa...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: System_Operations\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"Resource_Management\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: Resource_Management\n",
      "Raw LLM response: ```json\n",
      "{\n",
      "  \"category\": \"File_System_Errors\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"reasoning\": \"The log message ...\n",
      "Extracted JSON parsing successful\n",
      "Pydantic object created: File_System_Errors\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100058, Requested 827. Please try again in 12m45.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100058, Requested 785. Please try again in 12m8.806999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100058, Requested 785. Please try again in 12m8.623999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100058, Requested 776. Please try again in 12m0.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100057, Requested 784. Please try again in 12m7.362s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100057, Requested 776. Please try again in 12m0.259s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100057, Requested 846. Please try again in 13m0.56s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100057, Requested 784. Please try again in 12m6.815s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100056, Requested 813. Please try again in 12m31.677s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100056, Requested 787. Please try again in 12m9.037s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100056, Requested 773. Please try again in 11m56.769s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100056, Requested 771. Please try again in 11m54.828s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100056, Requested 794. Please try again in 12m14.513s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100055, Requested 788. Please try again in 12m9.141s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100055, Requested 788. Please try again in 12m8.965s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100055, Requested 754. Please try again in 11m39.413s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100055, Requested 771. Please try again in 11m53.927s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100055, Requested 772. Please try again in 11m54.612s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100054, Requested 755. Please try again in 11m39.743s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100054, Requested 787. Please try again in 12m7.219999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100054, Requested 787. Please try again in 12m7.043s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100054, Requested 826. Please try again in 12m40.559s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100054, Requested 785. Please try again in 12m4.958s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100053, Requested 790. Please try again in 12m9.091s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100053, Requested 776. Please try again in 11m56.821s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100053, Requested 776. Please try again in 11m56.644s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100053, Requested 784. Please try again in 12m3.377999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100053, Requested 790. Please try again in 12m8.368999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100052, Requested 805. Please try again in 12m21.139999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100052, Requested 865. Please try again in 13m12.796999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100052, Requested 776. Please try again in 11m55.731s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100052, Requested 844. Please try again in 12m54.304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100051, Requested 813. Please try again in 12m27.345s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100051, Requested 813. Please try again in 12m27.166s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100051, Requested 784. Please try again in 12m1.920999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100051, Requested 787. Please try again in 12m4.341s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100051, Requested 816. Please try again in 12m29.222s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100050, Requested 790. Please try again in 12m6.581s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100050, Requested 826. Please try again in 12m37.511s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100050, Requested 761. Please try again in 11m41.173s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100050, Requested 761. Please try again in 11m40.991s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100050, Requested 784. Please try again in 12m0.681s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100049, Requested 829. Please try again in 12m39.377999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100049, Requested 773. Please try again in 11m50.797999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100049, Requested 773. Please try again in 11m50.619s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100049, Requested 773. Please try again in 11m50.442s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100049, Requested 791. Please try again in 12m5.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100048, Requested 783. Please try again in 11m58.737s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100048, Requested 861. Please try again in 13m5.945999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100048, Requested 861. Please try again in 13m5.722s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100048, Requested 760. Please try again in 11m38.281999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100047, Requested 763. Please try again in 11m40.698s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100047, Requested 785. Please try again in 11m59.533s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100047, Requested 795. Please try again in 12m7.998s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100047, Requested 831. Please try again in 12m38.921s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100047, Requested 803. Please try again in 12m14.553s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100046, Requested 803. Please try again in 12m14.379s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100046, Requested 783. Please try again in 11m56.925s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100046, Requested 790. Please try again in 12m2.795999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100046, Requested 829. Please try again in 12m36.319999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100046, Requested 785. Please try again in 11m58.126s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100045, Requested 771. Please try again in 11m45.813s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100045, Requested 771. Please try again in 11m45.625s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100045, Requested 844. Please try again in 12m48.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100045, Requested 758. Please try again in 11m34.003999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100045, Requested 784. Please try again in 11m56.279s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100044, Requested 770. Please try again in 11m44.002s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100044, Requested 762. Please try again in 11m36.918s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100044, Requested 772. Please try again in 11m45.391s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100044, Requested 761. Please try again in 11m35.713s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100044, Requested 803. Please try again in 12m11.834s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100043, Requested 770. Please try again in 11m43.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100043, Requested 830. Please try again in 12m34.805999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100043, Requested 785. Please try again in 11m55.754s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100043, Requested 805. Please try again in 12m12.862s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100043, Requested 771. Please try again in 11m43.306s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100042, Requested 771. Please try again in 11m43.128999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100042, Requested 776. Please try again in 11m47.274s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100042, Requested 790. Please try again in 11m59.196s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100042, Requested 846. Please try again in 12m47.405s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100041, Requested 763. Please try again in 11m35.518s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100041, Requested 788. Please try again in 11m56.945999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100041, Requested 788. Please try again in 11m56.769s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100041, Requested 794. Please try again in 12m1.776999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100041, Requested 785. Please try again in 11m53.784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100040, Requested 781. Please try again in 11m50.132s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100040, Requested 785. Please try again in 11m53.406s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100040, Requested 788. Please try again in 11m55.826999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100040, Requested 788. Please try again in 11m55.657999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100040, Requested 763. Please try again in 11m33.885s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100039, Requested 785. Please try again in 11m52.69s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100039, Requested 800. Please try again in 12m5.475s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100039, Requested 761. Please try again in 11m31.602s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100039, Requested 761. Please try again in 11m31.428s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100039, Requested 865. Please try again in 13m1.084s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100038, Requested 835. Please try again in 12m34.994s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100038, Requested 786. Please try again in 11m52.49s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100038, Requested 762. Please try again in 11m31.577s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100038, Requested 777. Please try again in 11m44.362s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100038, Requested 772. Please try again in 11m39.866s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100037, Requested 848. Please try again in 12m45.363999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100037, Requested 784. Please try again in 11m49.896s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100037, Requested 770. Please try again in 11m37.625s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100037, Requested 770. Please try again in 11m37.453s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100037, Requested 785. Please try again in 11m50.24s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100036, Requested 776. Please try again in 11m42.291s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100036, Requested 785. Please try again in 11m49.892999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100036, Requested 785. Please try again in 11m49.709999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100036, Requested 785. Please try again in 11m49.487s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100035, Requested 1911. Please try again in 28m2.141999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100035, Requested 831. Please try again in 12m28.846s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100035, Requested 861. Please try again in 12m54.589999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100035, Requested 819. Please try again in 12m18.127999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100035, Requested 783. Please try again in 11m46.845s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100034, Requested 790. Please try again in 11m52.719999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100034, Requested 826. Please try again in 12m23.646s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100034, Requested 772. Please try again in 11m36.821s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100034, Requested 846. Please try again in 12m40.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100034, Requested 766. Please try again in 11m31.282999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100033, Requested 845. Please try again in 12m39.367s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100033, Requested 809. Please try again in 12m8.093s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100033, Requested 790. Please try again in 11m51.443s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100033, Requested 790. Please try again in 11m51.271s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100033, Requested 775. Please try again in 11m38.143s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100032, Requested 813. Please try again in 12m10.801s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100032, Requested 813. Please try again in 12m10.618s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100032, Requested 819. Please try again in 12m15.626s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100032, Requested 773. Please try again in 11m35.709s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100032, Requested 778. Please try again in 11m39.858s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100031, Requested 778. Please try again in 11m39.685999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100031, Requested 790. Please try again in 11m49.876s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100031, Requested 787. Please try again in 11m47.109s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100031, Requested 773. Please try again in 11m34.828s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100030, Requested 785. Please try again in 11m45.017s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100030, Requested 762. Please try again in 11m24.967s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100030, Requested 784. Please try again in 11m43.805s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100030, Requested 790. Please try again in 11m48.821s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100030, Requested 783. Please try again in 11m42.593999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100029, Requested 749. Please try again in 11m13.029s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100029, Requested 785. Please try again in 11m43.954s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100029, Requested 785. Please try again in 11m43.78s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100029, Requested 785. Please try again in 11m43.599s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100029, Requested 785. Please try again in 11m43.426999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100028, Requested 788. Please try again in 11m45.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100028, Requested 790. Please try again in 11m47.405s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100028, Requested 785. Please try again in 11m42.911999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100028, Requested 803. Please try again in 11m58.006s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100027, Requested 778. Please try again in 11m36.228999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100027, Requested 770. Please try again in 11m29.142999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100027, Requested 755. Please try again in 11m16.012s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100027, Requested 820. Please try again in 12m11.996s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100027, Requested 790. Please try again in 11m45.889s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100026, Requested 790. Please try again in 11m45.715999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100026, Requested 844. Please try again in 12m32.191s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100026, Requested 785. Please try again in 11m41.033s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100026, Requested 844. Please try again in 12m31.830999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100025, Requested 827. Please try again in 12m16.973s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100025, Requested 846. Please try again in 12m33.209s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100025, Requested 846. Please try again in 12m33.038s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100025, Requested 825. Please try again in 12m14.717s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100025, Requested 785. Please try again in 11m39.983999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100024, Requested 790. Please try again in 11m44.134s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100024, Requested 790. Please try again in 11m43.955s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100024, Requested 1911. Please try again in 27m52.3s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100024, Requested 759. Please try again in 11m16.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100024, Requested 755. Please try again in 11m13.17s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100023, Requested 769. Please try again in 11m25.09s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100023, Requested 769. Please try again in 11m24.921s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100023, Requested 819. Please try again in 12m7.955999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100023, Requested 790. Please try again in 11m42.675999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100023, Requested 776. Please try again in 11m30.406s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100022, Requested 776. Please try again in 11m30.223999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100022, Requested 790. Please try again in 11m42.14s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100022, Requested 805. Please try again in 11m54.907999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100022, Requested 787. Please try again in 11m39.185999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100022, Requested 819. Please try again in 12m6.66s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100021, Requested 827. Please try again in 12m13.398s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100021, Requested 781. Please try again in 11m33.479s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100021, Requested 781. Please try again in 11m33.303s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100021, Requested 816. Please try again in 12m3.358999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100021, Requested 787. Please try again in 11m38.117s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100020, Requested 766. Please try again in 11m19.807s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100020, Requested 771. Please try again in 11m23.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100020, Requested 771. Please try again in 11m23.769s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100020, Requested 775. Please try again in 11m27.047s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100020, Requested 772. Please try again in 11m24.288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100019, Requested 772. Please try again in 11m23.824999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100019, Requested 772. Please try again in 11m23.646999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100019, Requested 770. Please try again in 11m21.739999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100018, Requested 790. Please try again in 11m38.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100018, Requested 776. Please try again in 11m26.570999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100018, Requested 776. Please try again in 11m26.398s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100018, Requested 819. Please try again in 12m3.375s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100018, Requested 819. Please try again in 12m3.201s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100017, Requested 846. Please try again in 12m26.348999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100017, Requested 789. Please try again in 11m36.925s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100017, Requested 787. Please try again in 11m35.019s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100017, Requested 789. Please try again in 11m36.564s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100016, Requested 770. Please try again in 11m19.967s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100016, Requested 827. Please try again in 12m9.033s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100016, Requested 785. Please try again in 11m32.569999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100016, Requested 788. Please try again in 11m34.99s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100016, Requested 788. Please try again in 11m34.81s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100015, Requested 846. Please try again in 12m24.747s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100015, Requested 790. Please try again in 11m36.188s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100015, Requested 770. Please try again in 11m18.719999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100015, Requested 751. Please try again in 11m2.129s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100015, Requested 754. Please try again in 11m4.549s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100014, Requested 763. Please try again in 11m12.155s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100014, Requested 764. Please try again in 11m12.842s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100014, Requested 805. Please try again in 11m48.092s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100014, Requested 826. Please try again in 12m6.054s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100014, Requested 846. Please try again in 12m23.155s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100013, Requested 793. Please try again in 11m37.185s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100013, Requested 785. Please try again in 11m30.095999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100013, Requested 785. Please try again in 11m29.929s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100013, Requested 833. Please try again in 12m11.229999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100013, Requested 809. Please try again in 11m50.305999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100012, Requested 773. Please try again in 11m19.017s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100012, Requested 816. Please try again in 11m55.978999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100012, Requested 790. Please try again in 11m33.338s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100012, Requested 790. Please try again in 11m33.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100012, Requested 756. Please try again in 11m3.607s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100011, Requested 758. Please try again in 11m5.154s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100011, Requested 776. Please try again in 11m20.524s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100011, Requested 785. Please try again in 11m28.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100011, Requested 809. Please try again in 11m48.691999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100011, Requested 827. Please try again in 12m4.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100010, Requested 827. Please try again in 12m3.885s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100010, Requested 776. Please try again in 11m19.652999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100010, Requested 795. Please try again in 11m35.895s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100010, Requested 785. Please try again in 11m27.078s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100010, Requested 790. Please try again in 11m31.217s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100009, Requested 787. Please try again in 11m28.405s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100009, Requested 787. Please try again in 11m28.223999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100009, Requested 790. Please try again in 11m30.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100009, Requested 753. Please try again in 10m58.494s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100008, Requested 788. Please try again in 11m28.55s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100008, Requested 785. Please try again in 11m25.781s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100008, Requested 785. Please try again in 11m25.602s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100008, Requested 771. Please try again in 11m13.33s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100008, Requested 812. Please try again in 11m48.578s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100007, Requested 1911. Please try again in 27m37.931s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100007, Requested 776. Please try again in 11m17.122s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100007, Requested 788. Please try again in 11m27.313s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100007, Requested 758. Please try again in 11m1.217s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100007, Requested 785. Please try again in 11m24.369s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100006, Requested 784. Please try again in 11m23.323s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100006, Requested 763. Please try again in 11m5.006s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100006, Requested 844. Please try again in 12m14.811s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100006, Requested 844. Please try again in 12m14.634s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100006, Requested 788. Please try again in 11m26.070999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100005, Requested 794. Please try again in 11m31.065999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100005, Requested 794. Please try again in 11m30.891s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100005, Requested 826. Please try again in 11m58.362s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100005, Requested 826. Please try again in 11m58.183s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100005, Requested 790. Please try again in 11m26.891s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100004, Requested 846. Please try again in 12m15.093s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100004, Requested 777. Please try again in 11m15.292999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100004, Requested 777. Please try again in 11m15.087s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100004, Requested 754. Please try again in 10m55.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100003, Requested 750. Please try again in 10m51.404s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100003, Requested 750. Please try again in 10m51.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100003, Requested 783. Please try again in 11m19.557s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100003, Requested 771. Please try again in 11m9.011s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100003, Requested 781. Please try again in 11m17.473s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100002, Requested 781. Please try again in 11m17.295s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100002, Requested 785. Please try again in 11m20.574s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100002, Requested 785. Please try again in 11m20.393s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100002, Requested 761. Please try again in 10m59.476s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100002, Requested 785. Please try again in 11m20.028s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100001, Requested 785. Please try again in 11m19.853s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100001, Requested 785. Please try again in 11m19.679s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100001, Requested 787. Please try again in 11m21.226s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100001, Requested 785. Please try again in 11m19.319s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100001, Requested 776. Please try again in 11m11.355s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 825. Please try again in 11m53.514s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 825. Please try again in 11m53.338s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 803. Please try again in 11m34.156s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 826. Please try again in 11m53.853999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 844. Please try again in 12m9.22s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 788. Please try again in 11m20.654s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 805. Please try again in 11m35.158999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 783. Please try again in 11m15.974999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 790. Please try again in 11m21.849s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 757. Please try again in 10m53.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 757. Please try again in 10m52.98s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 757. Please try again in 10m52.805s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 805. Please try again in 11m34.1s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 826. Please try again in 11m52.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99998, Requested 826. Please try again in 11m51.882999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99998, Requested 776. Please try again in 11m8.506s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99998, Requested 772. Please try again in 11m4.868999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99998, Requested 785. Please try again in 11m15.920999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99998, Requested 760. Please try again in 10m54.143s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99997, Requested 756. Please try again in 10m50.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99997, Requested 756. Please try again in 10m50.324999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99997, Requested 785. Please try again in 11m15.198s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99997, Requested 785. Please try again in 11m15.017s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99997, Requested 789. Please try again in 11m18.29s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99996, Requested 789. Please try again in 11m18.116s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99996, Requested 760. Please try again in 10m52.884s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99996, Requested 760. Please try again in 10m52.664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99996, Requested 789. Please try again in 11m17.545s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99995, Requested 790. Please try again in 11m18.226s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99995, Requested 803. Please try again in 11m29.286s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99995, Requested 803. Please try again in 11m29.108999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99995, Requested 790. Please try again in 11m17.702s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99995, Requested 759. Please try again in 10m50.731s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99994, Requested 765. Please try again in 10m55.734s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99994, Requested 774. Please try again in 11m3.333s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99994, Requested 787. Please try again in 11m14.395s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99994, Requested 777. Please try again in 11m5.572s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99994, Requested 795. Please try again in 11m20.946s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99993, Requested 772. Please try again in 11m0.891s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99993, Requested 788. Please try again in 11m14.541s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99993, Requested 772. Please try again in 11m0.532s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99993, Requested 772. Please try again in 11m0.355999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99993, Requested 760. Please try again in 10m49.81s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99992, Requested 790. Please try again in 11m15.552s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99992, Requested 757. Please try again in 10m46.859s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99992, Requested 757. Please try again in 10m46.687s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99992, Requested 757. Please try again in 10m46.509s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99992, Requested 827. Please try again in 11m46.804s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99991, Requested 785. Please try again in 11m10.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99991, Requested 790. Please try again in 11m14.479s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99991, Requested 790. Please try again in 11m14.298s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99991, Requested 775. Please try again in 11m1.164s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99991, Requested 775. Please try again in 11m0.982s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 759. Please try again in 10m46.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 760. Please try again in 10m47.663s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 816. Please try again in 11m35.869s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 761. Please try again in 10m48.174s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99989, Requested 781. Please try again in 11m5.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99989, Requested 771. Please try again in 10m56.463s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99989, Requested 802. Please try again in 11m23.069s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99989, Requested 788. Please try again in 11m10.788s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99989, Requested 788. Please try again in 11m10.573s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99988, Requested 790. Please try again in 11m12.118999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99988, Requested 790. Please try again in 11m11.941s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99988, Requested 827. Please try again in 11m43.732s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99988, Requested 783. Please try again in 11m5.54s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99988, Requested 789. Please try again in 11m10.523s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99987, Requested 771. Please try again in 10m54.792999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99987, Requested 803. Please try again in 11m22.26s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99987, Requested 803. Please try again in 11m22.082s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99987, Requested 788. Please try again in 11m8.948s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99987, Requested 816. Please try again in 11m32.935s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99986, Requested 785. Please try again in 11m5.965s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99986, Requested 760. Please try again in 10m44.189s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99986, Requested 755. Please try again in 10m39.685s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99986, Requested 809. Please try again in 11m26.169s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99985, Requested 846. Please try again in 11m57.963s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99985, Requested 785. Please try again in 11m5.085999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99985, Requested 761. Please try again in 10m44.177s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99985, Requested 754. Please try again in 10m37.950999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99985, Requested 775. Please try again in 10m55.919s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99984, Requested 785. Please try again in 11m4.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99984, Requested 772. Please try again in 10m52.969999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99984, Requested 844. Please try again in 11m54.994s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99984, Requested 844. Please try again in 11m54.81s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99984, Requested 770. Please try again in 10m50.694s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99983, Requested 785. Please try again in 11m3.478s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99983, Requested 844. Please try again in 11m54.27s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99983, Requested 785. Please try again in 11m3.093999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99983, Requested 770. Please try again in 10m49.953s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99983, Requested 826. Please try again in 11m38.161999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99982, Requested 785. Please try again in 11m2.560999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in LLM call: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jy1tjf2hextbeqk1b4ejmhgs` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99982, Requested 785. Please try again in 11m2.377999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "# Process a substantial sample to validate consistency\n",
    "large_sample_size = 500\n",
    "large_sample_logs = unclassified_logs.head(large_sample_size)['raw_log_text'].tolist()\n",
    "\n",
    "print(f\"Processing large sample of {large_sample_size} logs with error subcategories...\")\n",
    "print(\"⏳ This will take about 15-20 minutes...\")\n",
    "print(\"This will give us reliable distribution statistics\")\n",
    "\n",
    "# Process large sample\n",
    "large_subcategory_results = process_batch_of_logs(\n",
    "    large_sample_logs, \n",
    "    llm, \n",
    "    subcategory_prompt,\n",
    "    delay=0.12  # Optimized speed\n",
    ")\n",
    "\n",
    "print(f\"\\nLarge sample processing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "faeec485-19ff-4eb8-bc05-2cb2f5ef2787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed: 65 logs\n",
      "Subcategory Distribution from 130 logs:\n",
      "  Boot_Timeout_Errors: 3 (4.6%)\n",
      "  Service_Communication_Errors: 7 (10.8%)\n",
      "  System_Operations: 5 (7.7%)\n",
      "  File_System_Errors: 13 (20.0%)\n",
      "  Scheduler_Operations: 1 (1.5%)\n",
      "  Network_Connection_Errors: 7 (10.8%)\n",
      "  Resource_Management: 8 (12.3%)\n",
      "  Configuration_Errors: 3 (4.6%)\n",
      "  Resource_Allocation_Errors: 1 (1.5%)\n",
      "  Network_Operations: 11 (16.9%)\n",
      "  Instance_Management: 3 (4.6%)\n",
      "  Unknown: 3 (4.6%)\n",
      "Average confidence: 0.793\n"
     ]
    }
   ],
   "source": [
    "# Analyze the results you already have\n",
    "successful_results = [r for r in large_subcategory_results if hasattr(r, 'category') and r.category != 'Error']\n",
    "\n",
    "print(f\"Successfully processed: {len(successful_results)} logs\")\n",
    "\n",
    "# Analyze distribution\n",
    "categories = [r.category for r in successful_results]\n",
    "from collections import Counter\n",
    "distribution = Counter(categories)\n",
    "\n",
    "print(\"Subcategory Distribution from 130 logs:\")\n",
    "for category, count in distribution.items():\n",
    "    print(f\"  {category}: {count} ({count/len(successful_results)*100:.1f}%)\")\n",
    "\n",
    "# Calculate average confidence\n",
    "confidences = [r.confidence for r in successful_results]\n",
    "avg_confidence = sum(confidences) / len(confidences)\n",
    "print(f\"Average confidence: {avg_confidence:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11643d3e-6aae-4dcc-a36e-479b6b8f7e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed: 62 logs\n",
      "LLM results saved!\n",
      "Logs with LLM classifications saved!\n"
     ]
    }
   ],
   "source": [
    "# Count successful results (filter out errors)\n",
    "successful_results = []\n",
    "for result in large_subcategory_results:\n",
    "    if hasattr(result, 'category') and result.category not in ['Error', 'Unknown']:\n",
    "        successful_results.append(result)\n",
    "\n",
    "print(f\"Successfully processed: {len(successful_results)} logs\")\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "import pandas as pd\n",
    "\n",
    "results_data = []\n",
    "for i, result in enumerate(successful_results):\n",
    "    results_data.append({\n",
    "        'log_index': i,\n",
    "        'llm_category': result.category,\n",
    "        'llm_confidence': result.confidence,\n",
    "        'llm_reasoning': result.reasoning\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv('../results/llm_classification_results_130_logs.csv', index=False)\n",
    "print(\"LLM results saved!\")\n",
    "\n",
    "# Also save the actual log texts that were classified\n",
    "processed_indices = unclassified_logs.head(len(successful_results)).index\n",
    "processed_logs = unclassified_logs.loc[processed_indices].copy()\n",
    "processed_logs['llm_category'] = [r.category for r in successful_results]\n",
    "processed_logs['llm_confidence'] = [r.confidence for r in successful_results]\n",
    "\n",
    "processed_logs.to_csv('../results/llm_classified_logs_with_text.csv', index=False)\n",
    "print(\"Logs with LLM classifications saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
